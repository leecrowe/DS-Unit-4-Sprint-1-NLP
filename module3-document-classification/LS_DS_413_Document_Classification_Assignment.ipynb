{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:   46.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
       "                         'clf__n_estimators': (5, 10),\n",
       "                         'vect__max_df': (0.75, 1.0),\n",
       "                         'vect__max_features': (500, 1000),\n",
       "                         'vect__min_df': (0.02, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 10 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   31.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=20, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('vect',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=1.0,\n",
       "                                                              max_features=None,\n",
       "                                                              min_df=1,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           2),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop_words='english...\n",
       "                                                                     random_state=None,\n",
       "                                                                     verbose=0,\n",
       "                                                                     warm_start=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__max_depth': (5, 10, 15, 20),\n",
       "                                        'clf__n_estimators': (5, 10),\n",
       "                                        'vect__max_df': (0.75, 1.0),\n",
       "                                        'vect__max_features': (500, 1000),\n",
       "                                        'vect__min_df': (0.02, 0.05)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(pipe, parameters, cv=20, n_jobs=-1, verbose=1)\n",
    "rand_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = rand_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':[5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=6)]: Done 135 out of 135 | elapsed: 18.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=1,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth_...\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=6,\n",
       "             param_grid={'clf__n_estimators': [5, 10, 20],\n",
       "                         'lsi__svd__n_components': [10, 100, 250],\n",
       "                         'lsi__vect__max_df': [0.9, 0.95, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    \n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_word_vectors(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-4.67550606e-02,  2.17486411e-01, -1.39248788e-01, -8.63811150e-02,\n",
       "         1.08062603e-01,  8.21812302e-02, -6.99262992e-02, -7.88967833e-02,\n",
       "        -4.63048331e-02,  1.67534256e+00, -8.29739422e-02,  8.47098455e-02,\n",
       "        -1.61168594e-02, -1.15673296e-01, -1.00931458e-01, -1.48674801e-01,\n",
       "        -2.86327489e-02,  1.00717258e+00, -8.84611458e-02, -3.00116055e-02,\n",
       "        -2.12408844e-02, -1.98691525e-03, -2.18204875e-02, -2.43686680e-02,\n",
       "        -8.50067884e-02, -5.28534129e-02, -3.88755389e-02,  2.85331737e-02,\n",
       "         9.71467644e-02, -1.52220830e-01, -7.67232990e-03,  3.68110649e-02,\n",
       "         3.03680412e-02, -3.20375822e-02,  4.51759845e-02, -2.22320929e-02,\n",
       "         2.99556088e-02, -3.53264883e-02, -8.09046626e-02,  4.02572937e-02,\n",
       "        -4.52380776e-02,  4.00653407e-02,  1.01217575e-01, -1.02363355e-01,\n",
       "         6.43703416e-02,  1.21800080e-01, -8.15031528e-02, -7.51190484e-02,\n",
       "         4.85178418e-02,  3.61067131e-02, -5.62809184e-02,  4.18828800e-02,\n",
       "        -9.56438202e-03, -1.31019577e-02,  6.11267164e-02, -5.16553111e-02,\n",
       "         3.51855718e-03, -5.93302697e-02,  1.33471452e-02, -5.46418168e-02,\n",
       "        -6.40768744e-03, -6.65486455e-02,  3.20854299e-02,  1.58353090e-01,\n",
       "        -7.78233483e-02, -9.54134837e-02,  3.75243835e-02,  3.79275940e-02,\n",
       "        -3.24006788e-02,  2.41587281e-01,  2.67855637e-02,  1.46980003e-01,\n",
       "         9.65503827e-02,  6.04135841e-02,  5.40188625e-02,  6.36219755e-02,\n",
       "         5.70697784e-02, -1.55114708e-02, -6.78861961e-02,  7.11889267e-02,\n",
       "        -4.57446128e-02,  1.15371859e-02, -6.99428171e-02,  3.00093442e-02,\n",
       "         1.31707115e-03, -2.86772579e-01,  3.16026181e-01,  1.96002334e-01,\n",
       "         1.60671636e-01,  4.46167700e-02,  5.54057732e-02, -1.77956037e-02,\n",
       "         1.57796994e-01,  3.04826107e-02,  1.18372798e-01,  3.78044136e-02,\n",
       "        -5.00417836e-02,  3.89910862e-02, -1.63217619e-01, -8.58448744e-02,\n",
       "         5.98485991e-02, -1.09544275e-02, -1.42839298e-01, -8.65477789e-03,\n",
       "        -2.82965209e-02, -6.20324790e-01,  2.65786629e-02, -1.53543660e-02,\n",
       "         2.16272488e-01,  2.55124606e-02, -3.01614776e-02, -1.43356591e-01,\n",
       "        -3.10345758e-02, -1.31078035e-01, -1.50374129e-01,  7.50435283e-03,\n",
       "         8.50384533e-02,  3.82597856e-02,  5.52595966e-02, -2.99246181e-02,\n",
       "         1.69796068e-02,  7.74004087e-02, -5.90990856e-02,  2.27499288e-02,\n",
       "        -5.20684943e-02,  8.32726732e-02,  7.28703439e-02, -7.48897195e-02,\n",
       "         5.74704297e-02, -3.18312570e-02,  1.59947369e-02, -8.15742239e-02,\n",
       "        -4.17144038e-02,  4.75331731e-02,  4.86046486e-02, -3.34403850e-03,\n",
       "         1.82459522e-02, -7.70179108e-02,  3.96432839e-02,  3.10516804e-02,\n",
       "        -1.03874719e+00,  1.90209791e-01,  1.62073895e-01,  1.03557028e-03,\n",
       "        -6.16472252e-02,  2.24926975e-02, -4.34726365e-02, -9.52140708e-03,\n",
       "         1.34421259e-01, -1.82343200e-02,  9.19859260e-02, -1.61238778e-02,\n",
       "         2.28434935e-01,  1.18926816e-01, -1.44609630e-01,  1.96701335e-03,\n",
       "        -9.02838260e-02, -6.16818592e-02, -1.84267424e-02,  8.16498548e-02,\n",
       "        -3.21386419e-02,  5.38884476e-02,  1.53115476e-02,  7.37509876e-02,\n",
       "        -1.06026091e-01, -1.16821699e-01, -2.18026191e-02, -1.10028177e-01,\n",
       "         8.91874656e-02,  1.50409834e-02,  7.72751868e-02,  1.25687540e-01,\n",
       "        -3.22907604e-02,  5.39286546e-02, -2.01050118e-01, -1.38029326e-02,\n",
       "        -8.34357813e-02, -9.00421664e-02,  8.96297097e-02, -1.48434430e-01,\n",
       "        -5.84306903e-02, -9.70491320e-02, -8.20585713e-03, -2.99466960e-02,\n",
       "         2.23509595e-03, -7.90550262e-02, -3.73679511e-02, -4.46197316e-02,\n",
       "         1.82006229e-02, -5.76254725e-02,  1.99167267e-03,  7.18337297e-02,\n",
       "         2.41990685e-02,  1.58399511e-02, -2.18793768e-02, -9.89985932e-03,\n",
       "         6.40814528e-02, -6.13718815e-02, -1.11674048e-01,  1.00324705e-01,\n",
       "        -1.00514688e-01, -9.24723148e-02, -7.25114122e-02, -1.28334416e-02,\n",
       "         1.66479394e-01,  8.65908712e-02,  2.51513086e-02,  2.05176771e-02,\n",
       "         9.89832655e-02,  3.87072854e-04, -1.31764382e-01, -2.33728327e-02,\n",
       "        -2.69102249e-02, -1.34848595e-01,  2.65630651e-02,  1.38402313e-01,\n",
       "        -1.66778490e-02,  1.03491629e-02, -4.97255474e-02,  7.57269934e-02,\n",
       "        -7.52002597e-02,  6.71452209e-02,  5.92398904e-02,  7.70933703e-02,\n",
       "         7.30587840e-02,  2.27728654e-02, -3.49727310e-02,  1.26141772e-01,\n",
       "         6.36828598e-03,  1.28286108e-01,  1.20686954e-02,  2.13961676e-02,\n",
       "         3.84524949e-02,  9.48235393e-02, -6.86500072e-02, -7.02346861e-02,\n",
       "        -6.99323267e-02, -1.58278033e-01,  5.16961403e-02,  4.71388437e-02,\n",
       "        -3.43012325e-02,  4.83978242e-02, -1.69183329e-01, -4.53796536e-02,\n",
       "         3.04854233e-02,  4.88160513e-02, -1.24649048e-01, -1.04970165e-01,\n",
       "        -8.64592418e-02,  5.51374108e-02,  7.81922042e-02, -2.92669926e-02,\n",
       "        -5.86480536e-02,  9.89177148e-04,  3.60662453e-02,  1.46576330e-01,\n",
       "         1.61460176e-01, -9.15234834e-02, -2.57627405e-02,  1.55300692e-01,\n",
       "         1.00190796e-01,  2.20081490e-02, -9.60066263e-03,  1.36905193e-01,\n",
       "        -3.22607867e-02, -2.12020967e-02, -6.17986731e-02, -6.14032932e-02,\n",
       "         2.10585240e-02,  6.25049090e-03, -8.59537944e-02, -6.55349642e-02,\n",
       "         3.72211002e-02, -1.40615165e-01, -1.96337953e-01, -2.05468144e-02,\n",
       "         1.31405825e-02,  9.84849259e-02, -4.83715311e-02,  2.18721494e-01,\n",
       "         2.50574440e-01,  4.39682454e-02,  9.89086553e-02, -1.03148304e-01,\n",
       "        -1.47065492e-02,  5.81453554e-02,  1.64416671e-01, -8.61592144e-02,\n",
       "         1.54656187e-01, -4.58907560e-02, -1.63037866e-01,  1.15813101e-02,\n",
       "        -3.74428593e-02,  1.42398439e-02, -1.43216491e-01,  1.80973131e-02,\n",
       "         7.47582933e-04, -2.09036931e-01, -7.23463818e-02,  4.28469256e-02],\n",
       "       dtype=float32),\n",
       " array([-1.92443579e-02,  2.06962377e-01, -5.62471934e-02, -2.90866550e-02,\n",
       "         7.92481005e-02, -1.39783544e-03, -2.48803124e-02, -5.70354164e-02,\n",
       "        -2.50450410e-02,  1.64183366e+00, -9.95873734e-02,  4.75371033e-02,\n",
       "        -1.09638348e-01, -1.09541826e-01, -1.34196682e-02, -1.09100901e-01,\n",
       "         7.94435292e-03,  1.10731578e+00, -5.74957691e-02, -1.12754613e-01,\n",
       "        -8.43776390e-02,  1.42281791e-02, -2.54506953e-02,  1.69516709e-02,\n",
       "        -1.28287962e-03, -9.52790454e-02,  4.32589017e-02,  5.55882081e-02,\n",
       "         8.12886432e-02, -1.43084288e-01,  1.88210933e-03,  6.44870251e-02,\n",
       "        -7.48979822e-02, -3.54245231e-02,  7.30950087e-02, -6.38069436e-02,\n",
       "         1.63749065e-02,  7.25410227e-03,  3.42306793e-02, -3.53914052e-02,\n",
       "         4.76560509e-03,  9.67684016e-02,  1.08335741e-01, -1.67975485e-01,\n",
       "         2.04899609e-01,  1.60644650e-01, -1.51903555e-01, -8.72699246e-02,\n",
       "         2.26206873e-02,  2.01791860e-02, -1.23800514e-02,  9.72665288e-03,\n",
       "         2.83039603e-02, -1.83670279e-02,  9.66785327e-02, -3.49727161e-02,\n",
       "        -1.13546895e-03, -6.73703402e-02, -1.01118855e-01, -9.55698267e-02,\n",
       "         1.63930003e-02, -7.02442899e-02, -2.77607255e-02,  1.89827129e-01,\n",
       "        -1.15782887e-01, -1.31347150e-01,  5.93079478e-02, -2.36396994e-02,\n",
       "        -1.24432147e-01,  2.23896012e-01, -5.07642142e-02,  1.38820440e-01,\n",
       "         1.05252370e-01,  1.38893733e-02,  9.14575998e-03,  1.07419871e-01,\n",
       "         1.73360668e-02, -1.68769863e-02, -8.12113658e-02,  6.62869513e-02,\n",
       "        -1.24771595e-02,  5.35291545e-02, -7.04220980e-02,  8.45311582e-02,\n",
       "         4.23822924e-02, -3.11599076e-01,  2.28412434e-01,  2.32660785e-01,\n",
       "         6.27093688e-02,  5.74577786e-02,  2.59114988e-02,  3.78410667e-02,\n",
       "         1.39491096e-01,  1.84117779e-02,  5.89284338e-02, -4.74029453e-03,\n",
       "        -2.15499420e-02, -1.09063862e-02, -1.22940794e-01, -5.12752123e-02,\n",
       "         5.96626662e-02, -1.88962799e-02, -1.31666511e-01, -4.74975221e-02,\n",
       "         4.47278209e-02, -7.08106339e-01,  1.00093372e-01,  3.73791084e-02,\n",
       "         1.69914976e-01, -9.14687440e-02, -7.25097954e-02, -1.24782167e-01,\n",
       "        -9.83926877e-02, -4.61759418e-02, -9.49799940e-02,  2.06474382e-02,\n",
       "         6.24357834e-02,  6.51602522e-02,  6.04532920e-02, -9.56575014e-03,\n",
       "        -1.48839259e-03,  4.85789478e-02, -1.04380243e-01, -5.21177016e-02,\n",
       "        -8.86223391e-02,  1.36632996e-03,  1.44861974e-02, -1.10969767e-01,\n",
       "         5.88850752e-02, -5.93315363e-02, -5.25692590e-02, -1.40417010e-01,\n",
       "         4.46418533e-03,  7.78552443e-02,  8.40416625e-02,  5.50224027e-03,\n",
       "         4.28637601e-02, -2.56229434e-02, -3.54412058e-03, -1.07177319e-02,\n",
       "        -1.07609892e+00,  2.17600137e-01,  1.99722007e-01,  6.44263402e-02,\n",
       "        -4.11977209e-02, -2.35874131e-02, -9.60707963e-02,  4.36630249e-02,\n",
       "         1.96539328e-01, -3.71673591e-02,  5.14325015e-02, -3.00984383e-02,\n",
       "         2.67972291e-01,  1.37300327e-01, -7.22049549e-02,  1.58618055e-02,\n",
       "        -1.34949714e-01, -1.68587919e-02,  2.33503878e-02, -1.97388120e-02,\n",
       "        -5.18814512e-02,  9.87320691e-02, -3.84725444e-03,  2.70832982e-02,\n",
       "        -9.54885408e-02, -1.82914972e-01,  5.39480485e-02, -8.44088271e-02,\n",
       "         1.13868885e-01,  3.19017619e-02,  7.43113682e-02,  2.76728366e-02,\n",
       "         1.52409810e-03, -1.68260897e-03, -1.11462735e-01,  7.15337396e-02,\n",
       "        -2.25165170e-02, -1.96362451e-01,  7.71895200e-02, -1.84280753e-01,\n",
       "        -4.89662178e-02, -7.31879622e-02, -5.11269532e-02, -1.06249869e-01,\n",
       "        -8.37948769e-02, -7.32675046e-02, -5.46207912e-02, -5.06748110e-02,\n",
       "         1.83292646e-02, -4.71153632e-02, -9.78108495e-02,  7.14154867e-03,\n",
       "        -4.15690094e-02,  1.06965132e-01,  5.13117611e-02,  8.42406228e-02,\n",
       "        -3.94255109e-03, -5.46640232e-02, -1.48153633e-01,  2.09303070e-02,\n",
       "        -9.55638811e-02, -1.16718775e-02, -1.29336789e-01, -1.83626134e-02,\n",
       "         1.21462032e-01,  5.45701049e-02,  4.59773839e-03,  2.39228681e-02,\n",
       "        -2.15486009e-02,  1.09996172e-02, -2.14492008e-01,  3.95465223e-03,\n",
       "         2.91320030e-02, -2.00149402e-01,  2.24013217e-02,  2.09999427e-01,\n",
       "        -6.79708272e-02,  1.04716411e-02,  1.45358145e-02,  4.96120080e-02,\n",
       "        -3.83016467e-02,  6.06033653e-02, -2.31795311e-02,  7.41450042e-02,\n",
       "         3.15395072e-02, -1.37976045e-02, -2.97150258e-02,  9.49979573e-02,\n",
       "         4.58117202e-02,  1.21525258e-01, -5.74670695e-02,  2.41706707e-02,\n",
       "        -2.08363235e-02,  6.61203712e-02, -1.29307374e-01, -2.27162819e-02,\n",
       "        -8.54330435e-02, -1.32020518e-01,  5.57513833e-02,  5.75322732e-02,\n",
       "         9.89373866e-03,  3.34687084e-02, -1.16466217e-01, -5.83618321e-02,\n",
       "        -2.03905385e-02, -2.16273665e-02, -1.38479084e-01, -9.28584859e-02,\n",
       "         4.75126930e-04, -3.97441126e-02,  2.65099239e-02, -4.85795327e-02,\n",
       "         7.60020409e-03, -6.73584873e-03, -1.92196388e-02,  2.75974482e-01,\n",
       "         1.78887039e-01, -1.23117752e-01, -3.41167040e-02,  1.79070041e-01,\n",
       "         4.27437425e-02,  2.31391732e-02, -8.42800364e-03,  9.98713151e-02,\n",
       "         4.39962111e-02, -7.54587278e-02, -8.71666819e-02, -5.11634313e-02,\n",
       "         7.72383288e-02,  1.81637630e-02,  5.97541295e-02,  2.10312586e-02,\n",
       "        -2.48727426e-02, -2.04481781e-01, -1.72330379e-01,  2.00895835e-02,\n",
       "        -1.64981522e-02,  6.50271922e-02,  2.65707937e-03,  2.51866192e-01,\n",
       "         2.55115002e-01,  3.75871919e-02,  1.67920180e-02, -1.21184185e-01,\n",
       "        -4.68073972e-02,  4.97643603e-03,  1.92068249e-01,  4.27927542e-03,\n",
       "         2.21056461e-01, -3.30859050e-02, -1.61042377e-01,  9.14758146e-02,\n",
       "        -4.50182669e-02, -1.10396847e-01, -1.27779633e-01,  2.94748507e-02,\n",
       "         5.49579933e-02, -1.38565183e-01, -6.70641139e-02,  6.54192567e-02],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-8f9308badb8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mveckt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mveckt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TfidVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "veckt = TfidVectorizer(stop_words='english', ngram_range=(1,2), max_features=10000)\n",
    "X_tfidf = veckt.fit_transform(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfc.predict(get_word_vectors(test['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X_tfidf.todense(), columns=veckt.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = ...predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 75% accuracy on the Kaggle competition. Once you have achieved 75% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    \n",
    "    Sentiment Analysis is the process of extracting feelings from text. This is helpful when trying to detemine how satisfied customers are based on surveys that they take or how people review items.\n",
    "    \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    \n",
    "    Maybe. I'm not totally sure and I'm a little fuzzy on these concepts. From what I can see they are at least similar in that they attempt to extract some kind of meaning from text. Document Classification might just be looking at the words, though, and how they compare to other documents. Whereas Sentiment Analysis classifies certain words themselves and tries to extract meaning from how those words are used in the given document. \n",
    "    \n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    \n",
    "    The labels are just the way we define something so we can extract meaning; they are not sentiment themselves.\n",
    "    \n",
    "    - What are common applications of sentiment analysis?\n",
    "    \n",
    "    Reviews, customer satisfaction for products/services, social media. Basically anything that people have gradiated views about.\n",
    "    \n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?\n",
    "    \n",
    "    A neural network is attempting to behave as we do. As processing power has become super cheap they have become more popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processor(words):\n",
    "    no_punc = [char for char in words if char not in string.punctuation]\n",
    "    no_punc = ''.join(no_punc)\n",
    "    \n",
    "    return [word for word in no_punc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_processor)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_processor at 0x0000018F088AC9D8>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':predictions})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
